<!DOCTYPE html><html lang="zh-Hans"><head><meta name="generator" content="Hexo 3.8.0"><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><meta name="theme-color" content="#f8f5ec"><meta name="msapplication-navbutton-color" content="#f8f5ec"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec"><meta name="referrer" content="same-origin"><meta name="referrer" content="no-referrer"><meta name="description" content="Hive的UDTF函数"><meta name="keywords" content="大数据,BigData,数据开发,Hadoop,Spark,Flink,Hive,HBase"><link rel="alternate" href="/cn/atom.xml" title="马攀的技术栈"><link rel="shortcut icon" type="image/x-icon" href="/cn/favicon.ico?v=2.11.0"><link rel="canonical" href="https://mapan.tech/cn/6be3.html"><link rel="stylesheet" type="text/css" href="/cn/css/style.css?v=2.11.0"><script>window.config={toc:!0,fancybox:!1,pjax:!1,latex:!1}</script><title>Hive的UDTF函数 - 马攀的技术栈</title></head><body><div id="mobile-navbar" class="mobile-navbar"><div class="mobile-header-logo"><a href="/cn/." class="logo">马攀的技术栈</a></div><div class="mobile-navbar-icon"><span></span> <span></span> <span></span></div></div><nav id="mobile-menu" class="mobile-menu slideout-menu"><ul class="mobile-menu-list"><a href="/cn/"><li class="mobile-menu-item">首页</li></a><a href="/cn/categories.html"><li class="mobile-menu-item">分类</li></a><a href="/cn/about.html"><li class="mobile-menu-item">关于</li></a><a href="/cn/message.html"><li class="mobile-menu-item">留言</li></a><a href="/cn/links.html"><li class="mobile-menu-item">友链</li></a></ul></nav><div class="container" id="mobile-panel"><header id="header" class="header"><div class="logo-wrapper"><a href="https://mapan.tech" class="logo">马攀的技术栈</a></div><nav class="site-navbar"><ul id="menu" class="menu"><li class="menu-item"><a class="menu-item-link" href="/cn/">首页</a></li><li class="menu-item"><a class="menu-item-link" href="/cn/categories.html">分类</a></li><li class="menu-item"><a class="menu-item-link" href="/cn/about.html">关于</a></li><li class="menu-item"><a class="menu-item-link" href="/cn/message.html">留言</a></li><li class="menu-item"><a class="menu-item-link" href="/cn/links.html">友链</a></li></ul></nav></header><main id="main" class="main"><div class="content-wrapper"><div id="content" class="content"><article class="post"><header class="post-header"><h1 class="post-title">Hive的UDTF函数</h1><div class="post-meta"><span class="post-time">2020-03-22 </span><span class="post-category"><a href="/cn/categories/数据仓库/">数据仓库</a> </span><span id="/cn/6be3.html" class="leancloud-visitors" data-flag-title="Hive的UDTF函数">阅读数 <span class="leancloud-visitors-count">1000</span> </span><span class="post-count">字数统计 1.4k </span><span class="post-count">阅读时长 6</span></div></header><div class="post-toc" id="post-toc"><h2 class="post-toc-title">文章目录</h2><div class="post-toc-content"><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#GenericUDTF-Interface"><span class="toc-text">GenericUDTF Interface</span></a></li></ol><li class="toc-item toc-level-2"><a class="toc-link" href="#Lateral-View-Syntax"><span class="toc-text">Lateral View Syntax</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Description"><span class="toc-text">Description</span></a></li></div></div><div class="post-content"><p>在一些应用场景中，需要对一个字段进行分割，形成多个字段，比如日志信息使用#号连接字段，那么在导入数据仓库的时候，使用UDTF函数就显得比较方便和得心应手了。<br>在Hive的官网上，可以看到最UDTF的介绍是这样的：</p><blockquote><h3 id="GenericUDTF-Interface"><a href="#GenericUDTF-Interface" class="headerlink" title="GenericUDTF Interface"></a>GenericUDTF Interface</h3><p>A custom UDTF can be created by extending the GenericUDTF abstract class and then implementing the initialize, process, and possibly close methods. The initialize method is called by Hive to notify the UDTF the argument types to expect. The UDTF must then return an object inspector corresponding to the row objects that the UDTF will generate. Once initialize() has been called, Hive will give rows to the UDTF using the process() method. While in process(), the UDTF can produce and forward rows to other operators by calling forward(). Lastly, Hive will call the close() method when all the rows have passed to the UDTF.</p></blockquote><p>那么自定义UDTF函数需要继承<code>GenericUDTF</code> 抽象方法，实现<code>initialize</code>，<code>process</code>，<code>close</code> 这三个方法。</p><p>其中<code>initialize</code>方法中声明了Hive中需要的参数类型。</p><p><code>process</code>方法中进行我们所期望的操作，并调用<code>forward</code>方法把内容写到hive对应的行中。</p><p>当所有的行都写完后，会执行<code>close</code>方法。</p><p>下面代码实现了输入一个String类型的字符串，输入分隔符。会按照分隔符分割，之后把内容进行输出。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> tech.mapan.hive.udtf;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hive.ql.exec.UDFArgumentException;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hive.ql.metadata.HiveException;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hive.ql.udf.generic.GenericUDTF;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorFactory;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hive.serde2.objectinspector.StructObjectInspector;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorFactory;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ExplodUDTF</span> <span class="keyword">extends</span> <span class="title">GenericUDTF</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> ArrayList&lt;String&gt; outList = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> StructObjectInspector <span class="title">initialize</span><span class="params">(StructObjectInspector argOIs)</span> <span class="keyword">throws</span> UDFArgumentException </span>&#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment">//1.定义输出数据的列名和类型</span></span><br><span class="line">        List&lt;String&gt; fieldNames = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        List&lt;ObjectInspector&gt; fieldOIs = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line"></span><br><span class="line">        <span class="comment">//2.添加输出数据的列名和类型</span></span><br><span class="line">        fieldNames.add(<span class="string">"lineToWord"</span>);</span><br><span class="line">        fieldOIs.add(PrimitiveObjectInspectorFactory.javaStringObjectInspector);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> ObjectInspectorFactory.getStandardStructObjectInspector(fieldNames, fieldOIs);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">process</span><span class="params">(Object[] args)</span> <span class="keyword">throws</span> HiveException </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//1.获取原始数据</span></span><br><span class="line">        String arg = args[<span class="number">0</span>].toString();</span><br><span class="line"></span><br><span class="line">        <span class="comment">//2.获取数据传入的第二个参数，此处为分隔符</span></span><br><span class="line">        String splitKey = args[<span class="number">1</span>].toString();</span><br><span class="line"></span><br><span class="line">        <span class="comment">//3.将原始数据按照传入的分隔符进行切分</span></span><br><span class="line">        String[] fields = arg.split(splitKey);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//4.遍历切分后的结果，并写出</span></span><br><span class="line">        <span class="keyword">for</span> (String field : fields) &#123;</span><br><span class="line"></span><br><span class="line">            <span class="comment">//集合为复用的，首先清空集合</span></span><br><span class="line">            outList.clear();</span><br><span class="line"></span><br><span class="line">            <span class="comment">//将每一个单词添加至集合</span></span><br><span class="line">            outList.add(field);</span><br><span class="line"></span><br><span class="line">            <span class="comment">//将集合内容写出</span></span><br><span class="line">            forward(outList);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">()</span> <span class="keyword">throws</span> HiveException </span>&#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>打好jar包并放到对应目录后，创建函数，尝试执行一句简单的，可以看到<code>1001#Jack#18#1999-01-02#Male</code>已经被按照期望的形式分割出来。其中<code>linetoword</code>是在UDTF函数中定义的列名</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; create <span class="keyword">function</span> mp_explod as <span class="string">"tech.mapan.hive.udtf.ExplodUDTF"</span>;</span><br><span class="line">OK</span><br><span class="line">Time taken: 0.03 seconds</span><br><span class="line"></span><br><span class="line">hive (default)&gt; select mp_explod(<span class="string">'1001#Jack#18#1999-01-02#Male'</span>,<span class="string">'#'</span>);</span><br><span class="line">OK</span><br><span class="line">linetoword</span><br><span class="line">1001</span><br><span class="line">Jack</span><br><span class="line">18</span><br><span class="line">1999-01-02</span><br><span class="line">Male</span><br><span class="line">Time taken: 12.29 seconds, Fetched: 5 row(s)</span><br></pre></td></tr></table></figure><p>实际上，UDF还有一种更直接的使用方法，可以直接把一个字段变成两个字段（或多个字段）输出，但这样的写法比较相对比较固定。其实在<code>initialize</code>方法里只需要多定义一个（或多个）字段即可，输出时，会自动按顺序填充到对应的字段位置上。写法如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> tech.mapan.hive.udtf;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hive.ql.exec.UDFArgumentException;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hive.ql.metadata.HiveException;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hive.ql.udf.generic.GenericUDTF;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorFactory;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hive.serde2.objectinspector.StructObjectInspector;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorFactory;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@program</span>: udtf</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@description</span>: UDTF函数,分割成两个字段</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span>: MaPan</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@create</span>: 2020-03-22 22:40</span></span><br><span class="line"><span class="comment"> **/</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ExplodUDTF2</span> <span class="keyword">extends</span> <span class="title">GenericUDTF</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> ArrayList&lt;String&gt; outList = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> StructObjectInspector <span class="title">initialize</span><span class="params">(StructObjectInspector argOIs)</span> <span class="keyword">throws</span> UDFArgumentException </span>&#123;</span><br><span class="line">        <span class="comment">// 1.定义输出数据的列名和类型</span></span><br><span class="line">        List&lt;String&gt; fieldNames = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2.添加输出数据的列名</span></span><br><span class="line">        fieldNames.add(<span class="string">"word1"</span>);</span><br><span class="line">        fieldNames.add(<span class="string">"word2"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3.定义输出数据的类型</span></span><br><span class="line">        List&lt;ObjectInspector&gt; fieldOIs = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        fieldOIs.add(PrimitiveObjectInspectorFactory.javaStringObjectInspector);</span><br><span class="line">        fieldOIs.add(PrimitiveObjectInspectorFactory.javaStringObjectInspector);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> ObjectInspectorFactory.getStandardStructObjectInspector(fieldNames, fieldOIs);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">process</span><span class="params">(Object[] args)</span> <span class="keyword">throws</span> HiveException </span>&#123;</span><br><span class="line">        <span class="comment">//1.获取原始数据</span></span><br><span class="line">        String arg = args[<span class="number">0</span>].toString();</span><br><span class="line"></span><br><span class="line">        <span class="comment">//2.获取数据传入的第二个参数，此处为分隔符</span></span><br><span class="line">        String splitKey = args[<span class="number">1</span>].toString();</span><br><span class="line"></span><br><span class="line">        <span class="comment">//3.将原始数据按照传入的分隔符进行切分</span></span><br><span class="line">        String[] fields = arg.split(splitKey);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//4.遍历切分后的结果，并写出</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">//集合为复用的，首先清空集合</span></span><br><span class="line">        outList.clear();</span><br><span class="line">        outList.add(fields[<span class="number">0</span>]);</span><br><span class="line">        outList.add(fields[<span class="number">1</span>]);</span><br><span class="line">        forward(outList);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">()</span> <span class="keyword">throws</span> HiveException </span>&#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>运行效果如下，这样就把一个字段直接拆成了两个字段。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">create <span class="keyword">function</span> mp_explod as <span class="string">"tech.mapan.hive.udtf.ExplodUDTF2"</span>;</span><br><span class="line">OK</span><br><span class="line">Time taken: 0.029 seconds</span><br><span class="line"></span><br><span class="line">hive (prac)&gt; select * from test03;</span><br><span class="line">OK</span><br><span class="line">test03.id	test03.name</span><br><span class="line">1001	jack<span class="comment">#ma</span></span><br><span class="line">1002	dong<span class="comment">#liu</span></span><br><span class="line">1003	poney<span class="comment">#ma</span></span><br><span class="line">Time taken: 0.522 seconds, Fetched: 3 row(s)</span><br><span class="line"></span><br><span class="line">hive (prac)&gt; select id,first_name,last_name from test03 lateral view mp_explod2(name,<span class="string">"#"</span>) temp as first_name,last_name;</span><br><span class="line">OK</span><br><span class="line">id	first_name	last_name</span><br><span class="line">1001	jack	ma</span><br><span class="line">1002	dong	liu</span><br><span class="line">1003	poney	ma</span><br><span class="line">Time taken: 13.393 seconds, Fetched: 3 row(s)</span><br></pre></td></tr></table></figure><p>补充一点：</p><p>关于Lateral View在官网这样介绍：</p><blockquote><h2 id="Lateral-View-Syntax"><a href="#Lateral-View-Syntax" class="headerlink" title="Lateral View Syntax"></a>Lateral View Syntax</h2><p><code>lateralView: LATERAL VIEW udtf(expression) tableAlias AS columnAlias (&#39;,&#39;columnAlias)*</code><br><code>fromClause: FROM baseTable (lateralView)*</code></p><h2 id="Description"><a href="#Description" class="headerlink" title="Description"></a>Description</h2><p>Lateral view is used in conjunction with user-defined table generating functions such as <code>explode()</code>. As mentioned in <a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+UDF#LanguageManualUDF-Built-inTable-GeneratingFunctions(UDTF">Built-in Table-Generating Functions</a>), a UDTF generates zero or more output rows for each input row. A lateral view first applies the UDTF to each row of base table and then joins resulting output rows to the input rows to form a virtual table having the supplied table alias.</p></blockquote><p>Lateral View一般与用户自定义表生成函数（如explode()）结合使用。 如<a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+UDF#LanguageManualUDF-Built-inTable-GeneratingFunctions(UDTF">内置表生成函数</a> 中所述，UDTF为每个输入行生成零个或多个输出行。 Lateral View 首先将UDTF应用于基表的每一行，然后将结果输出行连接到输入行，以形成具有提供的表别名的虚拟表。</p><p>附：<a href="6be3/udtf-1.0-SNAPSHOT.jar" target="_blank">jar包</a></p></div><div class="post-copyright"><p class="copyright-item"><span>原文作者: </span><a href="https://mapan.tech/cn">MaPan</a></p><p class="copyright-item"><span>原文链接: </span><a href="https://mapan.tech/cn/6be3.html">https://mapan.tech/cn/6be3.html</a></p><p class="copyright-item"><span>许可协议: </span><a rel="license" href="http://creativecommons.org/licenses/by-nc/4.0/" target="_blank">知识共享署名-非商业性使用 4.0 国际许可协议</a></p></div><footer class="post-footer"><nav class="post-nav"><a class="prev" href="/cn/a77d.html"><i class="iconfont icon-left"></i> <span class="prev-text nav-default">二分查找</span> <span class="prev-text nav-mobile">上一篇</span> </a><a class="next" href="/cn/d960.html"><span class="next-text nav-default">Hive的UDF函数</span> <span class="prev-text nav-mobile">下一篇</span> <i class="iconfont icon-right"></i></a></nav></footer></article></div><div class="comments" id="comments"><div id="vcomments"></div></div></div></main><footer id="footer" class="footer"><div class="social-links"><a href="/cn/atom.xml" class="iconfont icon-rss" title="rss" target="_blank"></a></div><div class="copyright"><span class="division">&nbsp;</span><span class="post-count"> 全站字数 89.6k </span><span class="copyright-year">Since 2015 <span class="heart"><i class="iconfont icon-heart"></i> </span><span class="author">MaPan</span></span></div></footer><div class="back-to-top" id="back-to-top"><i class="iconfont icon-up"></i></div></div><script src="./lib/valine/av-min.js?v=3.0.4"></script><script src="./lib/valine/Valine.min.js"></script><script type="text/javascript">new Valine({el:"#vcomments",notify:!1,verify:!0,app_id:"XtxvAXPwOzM9noIc3eyxi3AS-gzGzoHsz",app_key:"yEVQszyxb4bwLuAGU5VHnPR8",placeholder:"说点什么吧...",avatar:"mm",visitor:"ture"})</script><script type="text/javascript" src="/cn/lib/jquery/jquery.min.js"></script><script type="text/javascript" src="/cn/lib/slideout/slideout.js"></script><script type="text/javascript" src="/cn/js/src/even.js?v=2.11.0"></script></body></html>